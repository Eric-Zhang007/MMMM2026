# =========================
# DWTS / 2026 MCM C baseline
# =========================

data_path: "2026_MCM_Problem_C_Data.csv"
output_root: "outputs"
run_name: "dwts_baseline"
device: "cpu"     # "auto" -> 优先 cuda, 否则 xpu, 否则 cpu

features:
  use_homestate: true
  eps: 1e-6
  age_transform: "log_zscore"   # 你明确要求：log(age) 后再 z-score

model:
  # alpha = var_judge / (var_judge + k * var_fan + eps)
  k_variance_ratio: 1.0
  lambda_perf: 1.0

  # rank season 的 soft-rank 温度（越小越接近硬排名）
  tau_rank: 0.7

  # beta prior
  lambda_beta: 0.01
  beta_center: 1.0

  # phi regularization
  phi_reg: "elasticnet"         # {none, l1, l2, elasticnet}
  lambda_phi_l1: 0.001
  lambda_phi_l2: 0.001

  # theta/u priors（显式先验，AdamW weight_decay 不施加到它们）
  lambda_theta: 0.01
  lambda_u: 0.01

loss:
  xi_margin: 0.05
  xi_twist: 0.05
  xi_tb: 0.05

  # season>=28 twist loss weight
  lambdaA: 0.2
  lambdaB: 0.2
  twist_mode: "hinge"

training:
  train_mode: "all_train"       # 当前代码不分 train/val，直接全量
  epochs: 200
  lr: 0.001

  # 重要：AdamW 的 weight_decay 只作用在 phi 上（train.py 里 param_groups 已实现）
  weight_decay: 0.01

  grad_clip_norm: 1.0
  grad_accum_steps: 8
  patience: 20

  monitor: "train_ElimTop1Acc"  # 早停与 best 模型都按它（train_loss 也支持）
  resume_from: "none"           # {none,last,best,PATH}

  scheduler:
    type: "plateau"             # {none, plateau, warmup_cosine}
    plateau_factor: 0.5
    plateau_patience: 5
    min_lr: 1e-6
    # warmup_cosine 可选参数（type=warmup_cosine 时才用）
    warmup_steps: 0
    total_steps: 0

tune:
  enabled: false
  n_trials: 60
  n_jobs: "auto"                # auto -> 默认用 cpu-1 个进程（但如果用 GPU 会被强制降到 1）
  allow_parallel_gpu: false     # 单卡时不建议开 true

  # 为了调参速度，tune.py 会用更小的 epochs/patience（可自行调）
  epochs: 80
  patience: 10

  study_name: "dwts_tpe"
